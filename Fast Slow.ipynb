{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimentation on using Fast / Slow learning updates and life-long-learning as a method of long term memory.\n",
    "\n",
    "The idea here is that the weights of a neural network represent some kind of memory of the agents previous experience.  By using two networks, one with slow updates and one with fast updates we gain the ability to retain longterm information aswell as respond to short term changes.\n",
    "\n",
    "**Model Architecture**\n",
    "* todo...\n",
    "\n",
    "**Experiments**\n",
    "* Maze4x4\n",
    "* T-Maze\n",
    "* Random NxN partial information mazes\n",
    "\n",
    "**Notes**\n",
    "The fast and slow parts require backprop during *testing* aswell as training.  The muxer, however should be froozen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Setup our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# global parameters\n",
    "USE_CUDA = False\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our Fast / Slow model\n",
    "class Net(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dims, output_dims):\n",
    "        super().__init__()\n",
    "        \n",
    "        internal_dims = 64\n",
    "        \n",
    "        self.mux1 = nn.dense(internal_dims*2, internal_dims)\n",
    "        self.mux2 = nn.dense(internal_dims, output_dims)\n",
    "        \n",
    "        self.fast1 = nn.dense(input_dims, internal_dims)\n",
    "        self.fast2 = nn.dense(internal_dims, internal_dims)\n",
    "        \n",
    "        self.slow1 = nn.dense(input_dims, internal_dims)\n",
    "        self.slow2 = nn.dense(internal_dims, internal_dims)\n",
    "        \n",
    "    def fast_part(self, x):\n",
    "        x = nn.relu(self.fast1(x))\n",
    "        x = nn.relu(self.fast2(x))\n",
    "        return x        \n",
    "    \n",
    "    def slow_part(self, x):\n",
    "        x = nn.relu(self.slow1(x))\n",
    "        x = nn.relu(self.slow2(x))\n",
    "        return x        \n",
    "    \n",
    "    def muxer(self, slow, fast):\n",
    "        \"\"\" Combine fast and slow part \"\"\"\n",
    "        x = torch.cat((fast, slow), dim=1)\n",
    "        x = nn.relu(self.mux1(x))\n",
    "        x = self.mux2(x)\n",
    "        return F.log_softmax(x, dim=1)  \n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\" Run input through network. \"\"\"        \n",
    "        slow = self.slow_part(x)\n",
    "        fast = self.fast_part(x)\n",
    "        return self.muxer(slow, fast)\n",
    "        \n",
    "# the training loop\n",
    "def train(model, env, device, train_loader, optimizer, epoch, verbose=True):\n",
    "    model.train()\n",
    "    for i, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if verbose and i % 250 == 0:\n",
    "            print(\"Train Epoch: {} [{:.0f}%]\\tLoss: {:.6f}\".format(\n",
    "                epoch, 100 * i / len(train_loader), loss.item()))            \n",
    "            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 4x4 Maze with complete information\n",
    "\n",
    "This is just to make sure the algorithm is working..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 4x4 Maze with no Observation\n",
    "\n",
    "A 4x4 maze where agent is given no useful observations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 T-Maze\n",
    "\n",
    "T-Maze demonistrates the agents ability to retain important information at the start of an episode and apply it later on.\n",
    "\n",
    "LSTM units typically get ~70 steps on this task. See this [paper](https://papers.nips.cc/paper/1953-reinforcement-learning-with-long-short-term-memory.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#>> this is the code for policy updates...\n",
    "\n",
    "# Compute Values and Probability Distribution\n",
    "values, prob = self.ac_net(obs_tensor)\n",
    "\n",
    "# Compute Policy Gradient (Log probability x Action value)\n",
    "advantages = return_tensor - values\n",
    "action_log_probs = prob.log().gather(1, action_tensor)\n",
    "actor_loss = -(advantages.detach() * action_log_probs).mean()\n",
    "\n",
    "# Compute L2 loss for values\n",
    "critic_loss = advantages.pow(2).mean()\n",
    "\n",
    "# Backward Pass\n",
    "loss = actor_loss + critic_loss\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom learning rates for the network.\n",
    "\n",
    "optim = Adam(\n",
    "    [\n",
    "        {\"params\": model.fc.parameters(), \"lr\": 1e-3},\n",
    "        {\"params\": model.agroupoflayer.parameters()},\n",
    "        {\"params\": model.lastlayer.parameters(), \"lr\": 4e-2},\n",
    "    ],\n",
    "    lr=5e-4,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
